Running task 858 with seed=95 and percentage=0.25
Epoch 0, Loss Total: 84.06503295898438, Loss Train: 121.89745330810547, Loss Test: 134.3917694091797
Epoch 100, Loss Total: 45.381927490234375, Loss Train: 34.31678771972656, Loss Test: 71.64381408691406
Epoch 200, Loss Total: 41.20261001586914, Loss Train: 13.636564254760742, Loss Test: 44.156341552734375
Epoch 300, Loss Total: 44.77749252319336, Loss Train: 6.146789073944092, Loss Test: 36.47791290283203
Epoch 400, Loss Total: 48.25885772705078, Loss Train: 2.913587808609009, Loss Test: 34.193843841552734
Epoch 500, Loss Total: 50.87888717651367, Loss Train: 1.4149354696273804, Loss Test: 33.58243942260742
Epoch 600, Loss Total: 52.76961135864258, Loss Train: 0.6924784183502197, Loss Test: 33.51627731323242
Epoch 700, Loss Total: 54.1235466003418, Loss Train: 0.3370945155620575, Loss Test: 33.62010955810547
Epoch 800, Loss Total: 55.09389114379883, Loss Train: 0.16168533265590668, Loss Test: 33.76181411743164
Epoch 900, Loss Total: 55.791324615478516, Loss Train: 0.07591834664344788, Loss Test: 33.894378662109375
Epoch 1000, Loss Total: 56.29386520385742, Loss Train: 0.0347285158932209, Loss Test: 34.00331115722656
Epoch 1100, Loss Total: 56.65664291381836, Loss Train: 0.015416630543768406, Loss Test: 34.087257385253906
Epoch 1200, Loss Total: 56.91895294189453, Loss Train: 0.006623069755733013, Loss Test: 34.149681091308594
Epoch 1300, Loss Total: 57.108970642089844, Loss Train: 0.002753898734226823, Loss Test: 34.195213317871094
Epoch 1400, Loss Total: 57.24691390991211, Loss Train: 0.0011168255005031824, Loss Test: 34.22810745239258
Epoch 1500, Loss Total: 57.34727478027344, Loss Train: 0.00045292472350411117, Loss Test: 34.251773834228516
Epoch 1600, Loss Total: 57.42044448852539, Loss Train: 0.00019553682068362832, Loss Test: 34.268775939941406
Epoch 1700, Loss Total: 57.47388458251953, Loss Train: 9.99515104922466e-05, Loss Test: 34.2809944152832
Epoch 1800, Loss Total: 57.512969970703125, Loss Train: 6.54090617899783e-05, Loss Test: 34.289772033691406
Epoch 1900, Loss Total: 57.541595458984375, Loss Train: 5.326444443198852e-05, Loss Test: 34.29608917236328
Epoch 2000, Loss Total: 57.56257247924805, Loss Train: 4.8915972001850605e-05, Loss Test: 34.300636291503906
Epoch 2100, Loss Total: 57.577945709228516, Loss Train: 4.7374272980960086e-05, Loss Test: 34.30391311645508
Epoch 2200, Loss Total: 57.5892219543457, Loss Train: 4.67577156086918e-05, Loss Test: 34.306278228759766
Epoch 2300, Loss Total: 57.597496032714844, Loss Train: 4.648533649742603e-05, Loss Test: 34.30799102783203
Epoch 2400, Loss Total: 57.60355758666992, Loss Train: 4.634407378034666e-05, Loss Test: 34.309234619140625
Epoch 2500, Loss Total: 57.60797882080078, Loss Train: 4.649417314794846e-05, Loss Test: 34.31013488769531
Epoch 2600, Loss Total: 57.6112174987793, Loss Train: 4.6400662540690973e-05, Loss Test: 34.31078338623047
Epoch 2700, Loss Total: 57.61357498168945, Loss Train: 4.6269466110970825e-05, Loss Test: 34.311256408691406
Epoch 2800, Loss Total: 57.614540100097656, Loss Train: 4.627649832400493e-05, Loss Test: 34.31144714355469
Epoch 2900, Loss Total: 57.614967346191406, Loss Train: 4.627651651389897e-05, Loss Test: 34.31153106689453
Epoch 3000, Loss Total: 57.61516571044922, Loss Train: 4.627651287592016e-05, Loss Test: 34.31157302856445
Epoch 3100, Loss Total: 57.61526107788086, Loss Train: 4.6276520151877776e-05, Loss Test: 34.311588287353516
Epoch 3200, Loss Total: 57.615299224853516, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 3300, Loss Total: 57.615318298339844, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 3400, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 3500, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 3600, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 3700, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 3800, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 3900, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 4000, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 4100, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 4200, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 4300, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 4400, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 4500, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 4600, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 4700, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 4800, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 4900, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 5000, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 5100, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 5200, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 5300, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 5400, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 5500, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 5600, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 5700, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 5800, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 5900, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 6000, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 6100, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 6200, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 6300, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 6400, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 6500, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 6600, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 6700, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 6800, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 6900, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 7000, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 7100, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 7200, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 7300, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 7400, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 7500, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 7600, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 7700, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 7800, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 7900, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 8000, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 8100, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 8200, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 8300, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 8400, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 8500, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 8600, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 8700, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 8800, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 8900, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 9000, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 9100, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 9200, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 9300, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 9400, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 9500, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 9600, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 9700, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 9800, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 9900, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 10000, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 10100, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 10200, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 10300, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 10400, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 10500, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 10600, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 10700, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 10800, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 10900, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 11000, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 11100, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 11200, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 11300, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 11400, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 11500, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 11600, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 11700, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 11800, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 11900, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 12000, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 12100, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 12200, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 12300, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 12400, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 12500, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 12600, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 12700, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 12800, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 12900, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 13000, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 13100, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 13200, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 13300, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 13400, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 13500, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 13600, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 13700, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 13800, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 13900, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 14000, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 14100, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 14200, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 14300, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 14400, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 14500, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 14600, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 14700, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 14800, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 14900, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 15000, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 15100, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 15200, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 15300, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 15400, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 15500, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 15600, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 15700, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 15800, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 15900, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 16000, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 16100, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 16200, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 16300, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 16400, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 16500, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 16600, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 16700, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 16800, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 16900, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 17000, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 17100, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 17200, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 17300, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 17400, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 17500, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 17600, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 17700, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 17800, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 17900, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 18000, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 18100, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 18200, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 18300, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 18400, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 18500, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 18600, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 18700, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 18800, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 18900, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 19000, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 19100, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 19200, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 19300, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 19400, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 19500, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 19600, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 19700, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 19800, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Epoch 19900, Loss Total: 57.61532211303711, Loss Train: 4.627651287592016e-05, Loss Test: 34.31160354614258
Added results for seed=95 and percentage=0.25
Finished task 858
