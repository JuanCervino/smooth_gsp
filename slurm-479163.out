/var/spool/slurmd/job479163/slurm_script: line 3: _sobolev: command not found
Running task  with seed=0 and percentage=0.10
scripts/main_train.py:216: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.dataset is not 'paramAWDall_var_ep':
/home/ids/jpabon/miniconda3/envs/smooth_gsp/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Epoch 0, Loss Total: 124.15160369873047, Loss Train: 109.51587677001953, Loss Test: 125.77778625488281
Epoch 100, Loss Total: 8.770663261413574, Loss Train: 0.027970584109425545, Loss Test: 9.742074012756348
Epoch 200, Loss Total: 1.5590416193008423, Loss Train: 0.010818067006766796, Loss Test: 1.7310662269592285
Epoch 300, Loss Total: 0.5579208135604858, Loss Train: 0.009868471883237362, Loss Test: 0.618815541267395
Epoch 400, Loss Total: 0.3707031309604645, Loss Train: 0.009801388718187809, Loss Test: 0.4108032286167145
Epoch 500, Loss Total: 0.3235333263874054, Loss Train: 0.009773355908691883, Loss Test: 0.358395516872406
Epoch 600, Loss Total: 0.31166180968284607, Loss Train: 0.009770297445356846, Loss Test: 0.3452053368091583
Epoch 700, Loss Total: 0.3087420165538788, Loss Train: 0.009770402684807777, Loss Test: 0.3419610857963562
Epoch 800, Loss Total: 0.30766335129737854, Loss Train: 0.009770282544195652, Loss Test: 0.34076258540153503
Epoch 900, Loss Total: 0.3071836531162262, Loss Train: 0.009770234115421772, Loss Test: 0.3402296006679535
Epoch 1000, Loss Total: 0.3069496750831604, Loss Train: 0.009770211763679981, Loss Test: 0.33996960520744324
Epoch 1100, Loss Total: 0.3068300187587738, Loss Train: 0.009770197793841362, Loss Test: 0.33983665704727173
Epoch 1200, Loss Total: 0.3067672550678253, Loss Train: 0.009770193137228489, Loss Test: 0.3397669196128845
Epoch 1300, Loss Total: 0.3067339062690735, Loss Train: 0.009770183824002743, Loss Test: 0.3397298753261566
Epoch 1400, Loss Total: 0.3067161440849304, Loss Train: 0.009770181030035019, Loss Test: 0.33971017599105835
Epoch 1500, Loss Total: 0.30670684576034546, Loss Train: 0.009770180098712444, Loss Test: 0.33969980478286743
Epoch 1600, Loss Total: 0.30670180916786194, Loss Train: 0.009770180098712444, Loss Test: 0.33969423174858093
Epoch 1700, Loss Total: 0.3066992461681366, Loss Train: 0.009770180098712444, Loss Test: 0.3396913707256317
Epoch 1800, Loss Total: 0.3066979944705963, Loss Train: 0.009770180098712444, Loss Test: 0.3396899700164795
Epoch 1900, Loss Total: 0.306697279214859, Loss Train: 0.009770180098712444, Loss Test: 0.339689165353775
Epoch 2000, Loss Total: 0.30669698119163513, Loss Train: 0.009770180098712444, Loss Test: 0.33968880772590637
Epoch 2100, Loss Total: 0.3066968023777008, Loss Train: 0.009770180098712444, Loss Test: 0.33968865871429443
Epoch 2200, Loss Total: 0.3066968023777008, Loss Train: 0.009770180098712444, Loss Test: 0.33968865871429443
Epoch 2300, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 2400, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 2500, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 2600, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 2700, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 2800, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 2900, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 3000, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 3100, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 3200, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 3300, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 3400, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 3500, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 3600, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 3700, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 3800, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 3900, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 4000, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 4100, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 4200, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 4300, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 4400, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 4500, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 4600, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 4700, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 4800, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 4900, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 5000, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 5100, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 5200, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 5300, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 5400, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 5500, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 5600, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 5700, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 5800, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 5900, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 6000, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 6100, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 6200, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 6300, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 6400, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 6500, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 6600, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 6700, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 6800, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 6900, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 7000, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 7100, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 7200, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 7300, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 7400, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 7500, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 7600, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 7700, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 7800, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 7900, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 8000, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 8100, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 8200, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 8300, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 8400, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 8500, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 8600, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 8700, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 8800, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 8900, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 9000, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 9100, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 9200, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 9300, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 9400, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 9500, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 9600, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 9700, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 9800, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 9900, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 10000, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 10100, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 10200, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 10300, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 10400, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 10500, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 10600, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 10700, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 10800, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 10900, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 11000, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 11100, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 11200, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 11300, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 11400, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 11500, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 11600, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 11700, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 11800, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 11900, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 12000, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 12100, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 12200, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 12300, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 12400, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 12500, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 12600, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 12700, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 12800, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 12900, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 13000, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 13100, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 13200, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 13300, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 13400, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 13500, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 13600, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 13700, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 13800, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 13900, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 14000, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 14100, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 14200, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 14300, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 14400, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 14500, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 14600, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 14700, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 14800, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 14900, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 15000, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 15100, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 15200, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 15300, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 15400, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 15500, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 15600, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 15700, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 15800, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 15900, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 16000, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 16100, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 16200, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 16300, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 16400, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 16500, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 16600, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 16700, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 16800, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 16900, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 17000, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 17100, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 17200, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 17300, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 17400, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 17500, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 17600, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 17700, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 17800, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 17900, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 18000, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 18100, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 18200, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 18300, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 18400, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 18500, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 18600, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 18700, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 18800, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 18900, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 19000, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 19100, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 19200, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 19300, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 19400, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 19500, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 19600, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 19700, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 19800, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Epoch 19900, Loss Total: 0.30669674277305603, Loss Train: 0.009770180098712444, Loss Test: 0.33968862891197205
Added results for seed=0 and percentage=0.1
Finished task 
